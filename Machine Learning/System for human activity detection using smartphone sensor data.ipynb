{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQs69TJ76GwD"
   },
   "source": [
    "# System for human activity detection using smartphone sensor data\n",
    "\n",
    "**Author: Miguel Zabaleta (100463947)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vapTeEah6GVq"
   },
   "source": [
    "We will begin by describing the strategies that will be implemented and the reasoning behind them.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Part I: Original variables**\n",
    "\n",
    "First, I will try to get the best results just by using the features that we are initially given.\n",
    "\n",
    "In this section, we will make the following implementations (in principle, using default hyperparameters):\n",
    "\n",
    "**1.** Models **without an id column**, merging every sequence into a single dataset.\n",
    "\n",
    "  - 1.1. Gaussian Mixture Model\n",
    "\n",
    "  - 1.2. Classifiers\n",
    "    - Single models\n",
    "    - Ensemble of best models\n",
    "    - Ensemble of best models with tweaked parameters\n",
    "\n",
    "**2.** Models **with an id column**, indicating the person that is performing the actions (merging every sequence into a single dataset).  \n",
    "This could be a useful variable for the model to have since there is a lot of variability in the actions performed by different people (way of walking, for instance).\n",
    "\n",
    "- 2.1 Gaussian Mixture Model\n",
    "- 2.2 Classifiers (single models)\n",
    "\n",
    "**3.** Make **one model per sequence** (per person), and predict the test observations as the **majority class predicted among all the models**.  \n",
    "The reasoning is that if we do one model per sequence, we are avoiding the variability between the people, so maybe this way the individual model will be very good at predicting for their participant, and thus by selecting the majority class, the predictions for the test set (considered as different people than in the training) will also be very accurate.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Part II: MFCC variables**\n",
    "\n",
    "Secondly, let us advance that these implementations did not provide excellent results (around 0.8 accuracy).\n",
    "\n",
    "This can be due to the lack of relevant variables, as we are trying to differentiate between tasks with only 6 variables, where there is already a lot of variability in the movements and also overlap.\n",
    "\n",
    "To try to get better features, we will extract the **MFCC coefficients** and use them as our new variables, developing a similar implementation as before.\n",
    "\n",
    "For this implementation, we will try the following models:\n",
    "\n",
    "- 1. Gaussian Mixture Model\n",
    "- 2. Classifiers: ensemble of best models, trying **number of MFCC coefficients** from 5, 10, ..., 45\n",
    "\n",
    "<br>\n",
    "\n",
    "The third implementation regards selecting the **best combination of features** from which to construct the MFCC coefficients out of the 3 accelerometer variables and the 3 gyroscope variables.\n",
    "\n",
    "The thinking behind this is because getting 45 MFCC for every 6 variables didn't provide excellent results.  \n",
    "This may be because there are too many variables with high **multicolliniearity**, which would make it difficult for the models to differentiate between the signals.\n",
    "\n",
    "Maybe, we can find a group of 2 or 3 variables from which to construct the MFCC, and the right amount of MFCC too, which will provide excellent results after all.\n",
    "\n",
    "- 3. Selecting best combination of features (63 features combinations)\n",
    "  - 3.1. Gaussian Mixture Model\n",
    "  - 3.2. Classifiers: ensemble of best models, trying **number of MFCC coefficients** for 5, 10, 15, 20\n",
    "\n",
    "\n",
    "Now, let's begin by loading a set of packages and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hhu9p7r57W-B"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier,\n",
    "                            GradientBoostingClassifier, RandomForestClassifier, HistGradientBoostingClassifier,\n",
    "                             VotingRegressor, VotingClassifier)\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7CXvDN2t3Lt3"
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "ar_data = sio.loadmat('AR_database.mat', verify_compressed_data_integrity=False)\n",
    "data_train = ar_data['data_train'][:,0]\n",
    "label_train = ar_data['label_train'][:,0]\n",
    "data_test = ar_data['data_test'][:,0]\n",
    "label_test = ar_data['label_test'][:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLIhtEjEZzat"
   },
   "source": [
    "The models we will implement are the following:\n",
    "\n",
    "- Gaussian Mixture: as it has worked well in the past (using MFCC, but maybe it also works with raw signals)\n",
    "-  Linear Discriminant Analysis\n",
    "-  Quadratic Discriminant Analysis\n",
    "-    AdaBoost \n",
    "-    Bagging  \n",
    "-    Extra Trees\n",
    "-    Random Forest \n",
    "-    Hist Gradient Boosting\n",
    "-    LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G86Fs0IYpCMu"
   },
   "source": [
    "# Part 1. Original variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0ZlqrdrS9te"
   },
   "source": [
    "## 1. All observations together without id column\n",
    "\n",
    "First, we need to merge the sequences into a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RTfQaZqzbuBP"
   },
   "outputs": [],
   "source": [
    "X = data_train[0].T\n",
    "Y = label_train[0].T\n",
    "\n",
    "for k in range(1,8):\n",
    "  X = np.concatenate((X,data_train[k].T))\n",
    "  Y = np.concatenate((Y,label_train[k].T))\n",
    "\n",
    "X_real_test = data_test[0].T\n",
    "Y_real_test = label_test[0].T\n",
    "for k in range(3):\n",
    "  X_real_test = np.concatenate((X_real_test,data_test[k].T))\n",
    "  Y_real_test = np.concatenate((Y_real_test,label_test[k].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDXTh_i3aYLF"
   },
   "source": [
    "### 1.1. Gaussian Mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LmdYr7VXTDtE"
   },
   "outputs": [],
   "source": [
    "# convert datasets to dataframes for ease in implementation\n",
    "merge_train = np.append(X,Y,axis=1)\n",
    "merge_test = np.append(X_real_test,Y_real_test,axis=1)\n",
    "merge_train = pd.DataFrame(merge_train, columns = ['x1','y1','z1','x2','y2','z2','label'])\n",
    "merge_test = pd.DataFrame(merge_test, columns = ['x1','y1','z1','x2','y2','z2','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "MRbtX79ZUxBe",
    "outputId": "333a6cd8-de40-49c5-d78b-6d25527f0c9a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-766440fa-b809-4144-9af3-0f1cd76bd44a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.012817</td>\n",
       "      <td>-0.123217</td>\n",
       "      <td>0.102934</td>\n",
       "      <td>0.030191</td>\n",
       "      <td>0.066014</td>\n",
       "      <td>0.022859</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.022028</td>\n",
       "      <td>-0.124004</td>\n",
       "      <td>0.102102</td>\n",
       "      <td>0.035688</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.013250</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.023680</td>\n",
       "      <td>-0.125767</td>\n",
       "      <td>0.102814</td>\n",
       "      <td>0.047097</td>\n",
       "      <td>0.052343</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.017746</td>\n",
       "      <td>-0.127361</td>\n",
       "      <td>0.109386</td>\n",
       "      <td>0.050545</td>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.004325</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.016417</td>\n",
       "      <td>-0.125868</td>\n",
       "      <td>0.102473</td>\n",
       "      <td>0.047686</td>\n",
       "      <td>0.058189</td>\n",
       "      <td>0.017189</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-766440fa-b809-4144-9af3-0f1cd76bd44a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-766440fa-b809-4144-9af3-0f1cd76bd44a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-766440fa-b809-4144-9af3-0f1cd76bd44a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         x1        y1        z1        x2        y2        z2  label\n",
       "0  1.012817 -0.123217  0.102934  0.030191  0.066014  0.022859    4.0\n",
       "1  1.022028 -0.124004  0.102102  0.035688  0.074850  0.013250    4.0\n",
       "2  1.023680 -0.125767  0.102814  0.047097  0.052343  0.002553    4.0\n",
       "3  1.017746 -0.127361  0.109386  0.050545  0.049867  0.004325    4.0\n",
       "4  1.016417 -0.125868  0.102473  0.047686  0.058189  0.017189    4.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocROTjWzUWl3"
   },
   "outputs": [],
   "source": [
    "# train one model per label\n",
    "classes = np.unique(Y)\n",
    "nclasses = len(classes)\n",
    "\n",
    "models = []\n",
    "for i in range(nclasses):\n",
    "  data_train_class = merge_train.loc[merge_train['label'] == classes[i], ['x1','y1','z1','x2','y2','z2']]\n",
    "  gm = GaussianMixture(n_components=8, \n",
    "                        covariance_type='diag',\n",
    "                        random_state=100463947).fit(data_train_class)\n",
    "  models.append(gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osAWKWI1VI15",
    "outputId": "b5817921-6ddd-4bc1-885b-e899df9c451a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.73\n",
      "confusion matrix: \n",
      " [[15192     0   870     0     0]\n",
      " [    0 15069   992  3807   193]\n",
      " [    0   192 20103   306 12359]\n",
      " [    0  4004   257 15403   421]\n",
      " [    0   206  4061   430 11527]]\n"
     ]
    }
   ],
   "source": [
    "# predict based on highest loglike score\n",
    "scores = []\n",
    "for gmm in models:\n",
    "  loglike = gmm.score_samples(merge_test.iloc[:,[0,1,2,3,4,5]])\n",
    "  scores.append(loglike)\n",
    "pred_level = np.argmax(scores, axis=0)+1\n",
    "print('accuracy score:',np.round(accuracy_score(merge_test['label'],pred_level),2)) # 0.73\n",
    "print('confusion matrix:','\\n',confusion_matrix(merge_test['label'],pred_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exz0K7lkatdE"
   },
   "source": [
    "As we can see, in the whole dataset we achieve an **accuracy of 0.73**.  \n",
    "\n",
    "We can see that the easiest class to predict is laying (which seems reasonable), whereas climbing stairs is the hardest for this model to get right.\n",
    "\n",
    "Now, we will repeat the same process but for every test sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_aU5FmeBYOBp",
    "outputId": "f6ee0f7b-7b55-42c8-9fca-7ee98a510f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.72\n",
      "confusion matrix: \n",
      " [[3326    0    1    0    0]\n",
      " [   0 3950  223 1191   75]\n",
      " [   0   51 4827   57 2713]\n",
      " [   0 1844    9 3751  124]\n",
      " [   0   86 1031  184 3339]]\n",
      "accuracy score: 0.72\n",
      "confusion matrix: \n",
      " [[3997    0  867    0    0]\n",
      " [   0 3764  545  782   29]\n",
      " [   0   61 6301  126 4456]\n",
      " [   0   22   28 4058   84]\n",
      " [   0   19 1016   33 2388]]\n",
      "accuracy score: 0.79\n",
      "confusion matrix: \n",
      " [[4543    0    1    0    0]\n",
      " [   0 3405    1  643   14]\n",
      " [   0   29 4148   66 2477]\n",
      " [   0  294  211 3843   89]\n",
      " [   0   15  983   29 2461]]\n"
     ]
    }
   ],
   "source": [
    "for k in range(3):\n",
    "  test_seq = pd.DataFrame(data_test[k].T, columns = ['x1','y1','z1','x2','y2','z2'])\n",
    "  scores = []\n",
    "  for gmm in models:\n",
    "    loglike = gmm.score_samples(test_seq)\n",
    "    scores.append(loglike)\n",
    "  pred_level = np.argmax(scores, axis=0)+1\n",
    "  print('accuracy score:',np.round(accuracy_score(label_test[k].T,pred_level),2)) # 0.72, 0.72, 0.79\n",
    "  print('confusion matrix:','\\n',confusion_matrix(label_test[k].T,pred_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ap3Q7D5ubC3O"
   },
   "source": [
    "We can see that we get **0.72, 0.72, 0.79 respectives accuracies**, with similar difficulties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avv-0C1PbNte"
   },
   "source": [
    "### 1.2. Classification algorithms\n",
    "\n",
    "Now we will try each of the mentioned classifiers, evaluating the performance on the whole test set, and on the single sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6fMqV9TVPXk",
    "outputId": "3446eedb-e315-4774-b0f7-038b120a8e8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.539\n",
      "[[15198     0   864     0     0]\n",
      " [    0 12642  6711   708     0]\n",
      " [   10  3342 26644  2964     0]\n",
      " [    0  1654 16142  2289     0]\n",
      " [    9  2790 12101  1324     0]]\n",
      "accuracy over sequence 1: 0.506\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3290 1819  330    0]\n",
      " [   3  976 5800  869    0]\n",
      " [   0  827 3760 1141    0]\n",
      " [   0  985 3253  402    0]]\n",
      "accuracy over sequence 2: 0.555\n",
      "[[4000    0  864    0    0]\n",
      " [   0 3038 2078    4    0]\n",
      " [   4 1231 8828  881    0]\n",
      " [   0    0 4192    0    0]\n",
      " [   9  612 2494  341    0]]\n",
      "accuracy over sequence 3: 0.593\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3024  995   44    0]\n",
      " [   0  159 6216  345    0]\n",
      " [   0    0 4430    7    0]\n",
      " [   0  208 3101  179    0]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.74\n",
      "[[15900     0   162     0     0]\n",
      " [    0 11854  1021  6403   783]\n",
      " [    0   119 23318   103  9420]\n",
      " [    0   762   153 18193   977]\n",
      " [    0   181  7134   153  8756]]\n",
      "accuracy over sequence 1: 0.732\n",
      "[[3273    0   54    0    0]\n",
      " [   0 3043  233 1884  279]\n",
      " [   0   29 5554   22 2043]\n",
      " [   0  363    5 5098  262]\n",
      " [   0   62 1873   71 2634]]\n",
      "accuracy over sequence 2: 0.725\n",
      "[[4812    0   52    0    0]\n",
      " [   0 2918  545 1514  143]\n",
      " [   0   35 7218   35 3656]\n",
      " [   0   12   39 3970  171]\n",
      " [   0   40 1623    7 1786]]\n",
      "accuracy over sequence 3: 0.779\n",
      "[[4542    0    2    0    0]\n",
      " [   0 2850   10 1121   82]\n",
      " [   0   26 4992   24 1678]\n",
      " [   0   24  104 4027  282]\n",
      " [   0   17 1765    4 1702]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.556\n",
      "[[15198     0   864     0     0]\n",
      " [    0  5322  2214 10707  1818]\n",
      " [    2   581 14078 10525  7774]\n",
      " [    0    10     3 19086   986]\n",
      " [    1   641  4926  5791  4865]]\n",
      "accuracy over sequence 1: 0.526\n",
      "[[3327    0    0    0    0]\n",
      " [   0  778  834 3281  546]\n",
      " [   1   84 3279 2381 1903]\n",
      " [   0    5    0 5304  419]\n",
      " [   0  244 1391 1619 1386]]\n",
      "accuracy over sequence 2: 0.531\n",
      "[[4000    0  864    0    0]\n",
      " [   0 1733  545 2500  342]\n",
      " [   0  368 4389 3606 2581]\n",
      " [   0    0    0 4132   60]\n",
      " [   1  147 1121 1263  924]]\n",
      "accuracy over sequence 3: 0.655\n",
      "[[4544    0    0    0    0]\n",
      " [   0 2033    1 1645  384]\n",
      " [   0   45 3131 2157 1387]\n",
      " [   0    0    3 4346   88]\n",
      " [   0    6 1023 1290 1169]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.742\n",
      "[[16062     0     0     0     0]\n",
      " [    0 14460  1357  4045   199]\n",
      " [    4   122 26620   212  6002]\n",
      " [    0  4243  1004 14488   350]\n",
      " [    0    87  9258   266  6613]]\n",
      "accuracy over sequence 1: 0.678\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3421  388 1563   67]\n",
      " [   1   30 6181   38 1398]\n",
      " [   0 1994  206 3439   89]\n",
      " [   0   33 2703  107 1797]]\n",
      "accuracy over sequence 2: 0.801\n",
      "[[4864    0    0    0    0]\n",
      " [   0 3786  564  723   47]\n",
      " [   0   50 8752   92 2050]\n",
      " [   0   61   78 3975   78]\n",
      " [   0   15 1900   33 1508]]\n",
      "accuracy over sequence 3: 0.818\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3832   17  196   18]\n",
      " [   2   12 5506   44 1156]\n",
      " [   0  194  514 3635   94]\n",
      " [   0    6 1952   19 1511]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.727\n",
      "[[15204     0   858     0     0]\n",
      " [    0 14174  1254  4509   124]\n",
      " [    0    69 27314   183  5394]\n",
      " [    0  4234  2690 12883   278]\n",
      " [    0    49  8828   289  7058]]\n",
      "accuracy over sequence 1: 0.656\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3178  350 1863   48]\n",
      " [   0   24 6330   32 1262]\n",
      " [   0 2007  797 2825   99]\n",
      " [   0   24 2581  124 1911]]\n",
      "accuracy over sequence 2: 0.786\n",
      "[[4006    0  858    0    0]\n",
      " [   0 3879  546  684   11]\n",
      " [   0   16 8913   83 1932]\n",
      " [   0   31   85 4043   33]\n",
      " [   0    1 1812   24 1619]]\n",
      "accuracy over sequence 3: 0.818\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3939    8   99   17]\n",
      " [   0    5 5741   36  938]\n",
      " [   0  189 1011 3190   47]\n",
      " [   0    0 1854   17 1617]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.744\n",
      "[[16062     0     0     0     0]\n",
      " [    0 14284  1203  4387   187]\n",
      " [    0    52 27292   161  5455]\n",
      " [    0  3970  2201 13617   297]\n",
      " [    0    52  8789   200  7183]]\n",
      "accuracy over sequence 1: 0.675\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3268  322 1789   60]\n",
      " [   0   16 6357   27 1248]\n",
      " [   0 1875  552 3197  104]\n",
      " [   0   23 2590   89 1938]]\n",
      "accuracy over sequence 2: 0.816\n",
      "[[4864    0    0    0    0]\n",
      " [   0 3864  549  658   49]\n",
      " [   0   16 8884   72 1972]\n",
      " [   0    2  104 4055   31]\n",
      " [   0    3 1800   15 1638]]\n",
      "accuracy over sequence 3: 0.815\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3884   10  151   18]\n",
      " [   0    4 5694   35  987]\n",
      " [   0  218  993 3168   58]\n",
      " [   0    3 1809    7 1669]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.72\n",
      "[[13585   604  1872     0     1]\n",
      " [   24 12902  2273  4687   175]\n",
      " [   15   115 26273   247  6310]\n",
      " [    0  4167   580 14628   710]\n",
      " [    3    86  7322   314  8499]]\n",
      "accuracy over sequence 1: 0.646\n",
      "[[2684   30  613    0    0]\n",
      " [  12 2595  862 1896   74]\n",
      " [   0   30 6111   56 1451]\n",
      " [   0 1994   82 3497  155]\n",
      " [   0   34 2063  139 2404]]\n",
      "accuracy over sequence 2: 0.803\n",
      "[[4803   60    0    0    1]\n",
      " [   0 3790  545  766   19]\n",
      " [  14   45 8503   90 2292]\n",
      " [   0   42   76 4035   39]\n",
      " [   3   14 1593   20 1826]]\n",
      "accuracy over sequence 3: 0.789\n",
      "[[3414  484  646    0    0]\n",
      " [   0 3922    4  129    8]\n",
      " [   1   10 5548   45 1116]\n",
      " [   0  137  340 3599  361]\n",
      " [   0    4 1603   16 1865]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.533\n",
      "[[15199     0   863     0     0]\n",
      " [    0 13370  6687     4     0]\n",
      " [    3  5365 27576    16     0]\n",
      " [    0  4095 15990     0     0]\n",
      " [    4  3887 12333     0     0]]\n",
      "accuracy over sequence 1: 0.485\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3482 1955    2    0]\n",
      " [   1 1474 6168    5    0]\n",
      " [   0 2044 3684    0    0]\n",
      " [   0 1251 3389    0    0]]\n",
      "accuracy over sequence 2: 0.575\n",
      "[[4001    0  863    0    0]\n",
      " [   0 3341 1779    0    0]\n",
      " [   1 1842 9096    5    0]\n",
      " [   0    0 4192    0    0]\n",
      " [   4  833 2619    0    0]]\n",
      "accuracy over sequence 3: 0.591\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3065  998    0    0]\n",
      " [   0  575 6144    1    0]\n",
      " [   0    7 4430    0    0]\n",
      " [   0  552 2936    0    0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    AdaBoostClassifier(random_state=100463947), \n",
    "    BaggingClassifier(random_state=100463947), \n",
    "    ExtraTreesClassifier(random_state=100463947),\n",
    "    RandomForestClassifier(random_state=100463947), \n",
    "    HistGradientBoostingClassifier(random_state=100463947),\n",
    "    LinearSVC(random_state=100463947)\n",
    "    ]\n",
    "\n",
    "i=0\n",
    "for clf in classifiers:\n",
    "    print('model',str(clf))\n",
    "    \n",
    "    clf.fit(X,Y.ravel())\n",
    "    pred = clf.predict(X_real_test)\n",
    "    print(\"accuracy over all sequences:\",round(metrics.accuracy_score(Y_real_test,pred),3))\n",
    "    print(metrics.confusion_matrix(Y_real_test, pred))\n",
    "\n",
    "    for k in range(3):\n",
    "      y_test_pred = clf.predict(data_test[k].T)\n",
    "      print('accuracy over sequence ',k+1,': ',round(metrics.accuracy_score(label_test[k].T, y_test_pred),3),sep='')\n",
    "      print(metrics.confusion_matrix(label_test[k].T, y_test_pred))\n",
    "    \n",
    "    i=i+1\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zINQIuXtf_oB"
   },
   "source": [
    "We have that the best models are the following: **QDA, Bagging, GB, RF, HGB**\n",
    "\n",
    "Let's try an ensemble of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46GeOkLbp-nb",
    "outputId": "5694acc2-9c33-46df-f9b8-7646cfb920d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.766\n",
      "[[16060     0     2     0     0]\n",
      " [    0 14288  1218  4376   179]\n",
      " [    0    64 27163   175  5558]\n",
      " [    0  3651   635 15425   374]\n",
      " [    0    62  8185   230  7747]]\n",
      "accuracy over sequence 1: 0.704\n",
      "[[3326    0    1    0    0]\n",
      " [   0 3309  333 1737   60]\n",
      " [   0   18 6307   29 1294]\n",
      " [   0 1773   70 3761  124]\n",
      " [   0   25 2348  103 2164]]\n",
      "accuracy over sequence 2: 0.813\n",
      "[[4864    0    0    0    0]\n",
      " [   0 3779  546  747   48]\n",
      " [   0   22 8796   78 2048]\n",
      " [   0    0   77 4062   53]\n",
      " [   0    6 1700   15 1735]]\n",
      "accuracy over sequence 3: 0.848\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3891    6  155   11]\n",
      " [   0    6 5753   39  922]\n",
      " [   0  105  418 3841   73]\n",
      " [   0    6 1789    9 1684]]\n"
     ]
    }
   ],
   "source": [
    "# ensemble with soft voting\n",
    "classifiers = [\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    BaggingClassifier(random_state=100463947), \n",
    "    GradientBoostingClassifier(random_state=100463947), \n",
    "    RandomForestClassifier(random_state=100463947), \n",
    "    HistGradientBoostingClassifier(random_state=100463947)\n",
    "    ]\n",
    "initials = ['QDA','Bagg','GB','RF','HGB']\n",
    "\n",
    "e_list = [(i,c) for i,c in zip(initials,classifiers)]\n",
    "\n",
    "eclf = VotingClassifier(estimators=e_list, voting='soft')\n",
    "eclf.fit(X,Y.ravel())\n",
    "pred = eclf.predict(X_real_test)\n",
    "score = round(metrics.accuracy_score(Y_real_test, pred),3)\n",
    "print(score)\n",
    "print(metrics.confusion_matrix(Y_real_test, pred))\n",
    "\n",
    "for k in range(3):\n",
    "      y_test_pred = eclf.predict(data_test[k].T)\n",
    "      print('accuracy over sequence ',k+1,': ',round(metrics.accuracy_score(label_test[k].T, y_test_pred),3),sep='')\n",
    "      print(metrics.confusion_matrix(label_test[k].T, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6sBXJi1bakG"
   },
   "source": [
    "We have **improved** our score to **0.766 accuracy overall**, and **0.704, 0.813, 0.848 accuracies** for the respective sequences.\n",
    "\n",
    "In this case, it is clear that the laying activity is almost perfectly classified, whereas the hardest for this ensemble is walking.\n",
    "\n",
    "Let's do a brief **manual hyperparameter tuning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CHvNsVR9mpzU",
    "outputId": "c63351f3-e9a0-40e0-b5d5-bc046ff8b47a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.771\n",
      "[[16062     0     0     0     0]\n",
      " [    0 14080  1321  4470   190]\n",
      " [    0    44 29330   150  3436]\n",
      " [    0  2983   670 16101   331]\n",
      " [    0    80 10224   191  5729]]\n",
      "accuracy over sequence 1: 0.712\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3331  375 1676   57]\n",
      " [   0   14 6788   25  821]\n",
      " [   0 1479  103 4023  123]\n",
      " [   0   33 2917   85 1605]]\n",
      "accuracy over sequence 2: 0.817\n",
      "[[4864    0    0    0    0]\n",
      " [   0 3619  557  888   56]\n",
      " [   0   10 9563   63 1308]\n",
      " [   0    0  116 4034   42]\n",
      " [   0    9 2169   11 1267]]\n",
      "accuracy over sequence 3: 0.852\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3799   14  230   20]\n",
      " [   0    6 6191   37  486]\n",
      " [   0   25  348 4021   43]\n",
      " [   0    5 2221   10 1252]]\n"
     ]
    }
   ],
   "source": [
    "# now, manually tweak the parameters try to achieve better results\n",
    "classifiers = [\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    BaggingClassifier(n_estimators=200,max_features=6,max_samples=1500,random_state=100463947), \n",
    "    GradientBoostingClassifier(learning_rate=0.0001,n_estimators=2000,min_samples_split=100,random_state=100463947), \n",
    "    RandomForestClassifier(n_estimators=2000,max_depth=200,random_state=100463947), \n",
    "    HistGradientBoostingClassifier(learning_rate=0.0001,max_iter=2000,max_depth=200,random_state=100463947)\n",
    "    ]\n",
    "initials = ['QDA','Bagg','GB','RF','HGB']\n",
    "\n",
    "e_list = [(i,c) for i,c in zip(initials,classifiers)]\n",
    "\n",
    "eclf = VotingClassifier(estimators=e_list, voting='soft')\n",
    "eclf.fit(X,Y.ravel())\n",
    "pred = eclf.predict(X_real_test)\n",
    "score = round(metrics.accuracy_score(Y_real_test, pred),3)\n",
    "print(score)\n",
    "print(metrics.confusion_matrix(Y_real_test, pred))\n",
    "\n",
    "for k in range(3):\n",
    "      y_test_pred = eclf.predict(data_test[k].T)\n",
    "      print('accuracy over sequence ',k+1,': ',round(metrics.accuracy_score(label_test[k].T, y_test_pred),3),sep='')\n",
    "      print(metrics.confusion_matrix(label_test[k].T, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AQxsdnwTr2zH"
   },
   "source": [
    "Yet again, we have managed to **improve our scores** to **0.771 overall accuracy**, and **0.712, 0.817, 0.852** for the respective sequence accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlMtB2c7r-Po"
   },
   "source": [
    "## 2. Adding 'id' column per sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqwQ8R2UeFxy"
   },
   "outputs": [],
   "source": [
    "# re-load data\n",
    "import scipy.io as sio\n",
    "ar_data = sio.loadmat('AR_database.mat', verify_compressed_data_integrity=False)\n",
    "data_train = ar_data['data_train'][:,0]\n",
    "label_train = ar_data['label_train'][:,0]\n",
    "data_test = ar_data['data_test'][:,0]\n",
    "label_test = ar_data['label_test'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RFcfPuJSud3t"
   },
   "outputs": [],
   "source": [
    "for k in range(data_train.shape[0]):\n",
    "  m = data_train[k].shape[1] # numer of observations\n",
    "  a = data_train[k].T # change dimension to match append\n",
    "  b = np.array([np.repeat(str(k+1),m)]).T # add 'id' column of 1's, 2's,..., 8's for the observations of each sequence\n",
    "  data_train[k] = np.append(a,b,axis=1)\n",
    "\n",
    "for k in range(data_test.shape[0]):\n",
    "  m = data_test[k].shape[1] \n",
    "  a = data_test[k].T \n",
    "  b = np.array([np.repeat(str(k+9),m)]).T \n",
    "  data_test[k] = np.append(a,b,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJjuOFmhiVfN"
   },
   "outputs": [],
   "source": [
    "X = data_train[0]\n",
    "Y = label_train[0].T\n",
    "\n",
    "for k in range(1,8):\n",
    "  X = np.concatenate((X,data_train[k]))\n",
    "  Y = np.concatenate((Y,label_train[k].T))\n",
    "\n",
    "X_real_test = data_test[0]\n",
    "Y_real_test = label_test[0].T\n",
    "for k in range(3):\n",
    "  X_real_test = np.concatenate((X_real_test,data_test[k]))\n",
    "  Y_real_test = np.concatenate((Y_real_test,label_test[k].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WW2NV82Bg8Yc"
   },
   "source": [
    "### 2.1 Gaussian Mixture Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GCCIrfvgqzD"
   },
   "outputs": [],
   "source": [
    "# Gaussian Mixture implementation\n",
    "merge_train = np.append(X,Y,axis=1)\n",
    "merge_test = np.append(X_real_test,Y_real_test,axis=1)\n",
    "merge_train = pd.DataFrame(merge_train, columns = ['x1','y1','z1','x2','y2','z2','id','label'])\n",
    "merge_test = pd.DataFrame(merge_test, columns = ['x1','y1','z1','x2','y2','z2','id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buhQB42QgqzE"
   },
   "outputs": [],
   "source": [
    "# train one model per label\n",
    "classes = np.unique(Y)\n",
    "nclasses = len(classes)\n",
    "\n",
    "models = []\n",
    "for i in range(nclasses):\n",
    "  data_train_class = merge_train.loc[merge_train['label'] == str(classes[i]), ['x1','y1','z1','x2','y2','z2','id']]\n",
    "  gm = GaussianMixture(n_components=8, \n",
    "                        covariance_type='diag',\n",
    "                        random_state=100463947).fit(data_train_class)\n",
    "  models.append(gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XRmfafDKgqzE",
    "outputId": "02fc30fc-043f-4038-d761-790bc134420c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.31\n"
     ]
    }
   ],
   "source": [
    "# predict based on highest loglike score\n",
    "scores = []\n",
    "for gmm in models:\n",
    "  loglike = gmm.score_samples(merge_test.iloc[:,[0,1,2,3,4,5,6]])\n",
    "  scores.append(loglike)\n",
    "pred_level = np.argmax(scores, axis=0)+1\n",
    "print('accuracy score:',np.round(accuracy_score(merge_test['label'].astype('int'),pred_level),2)) # 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI88naphisYU"
   },
   "source": [
    "We get an accuracy score of 0.31, predicting the label 3 (climbing stairs) every time.  \n",
    "This is probably due to the way the 'id' variable is implemented in the Gaussian Mixture model.\n",
    "\n",
    "As it's codified as a string variable, in the test set it has values that it has never seen before.\n",
    "\n",
    "This probably confuses the model a lot and therefore tries to predict the most frequent class as the most likely to be statistically similar to the test observations.\n",
    "\n",
    "We will now implement the classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opEluptEhC1E"
   },
   "source": [
    "### 2.2 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bG6hTeb4iVfU",
    "outputId": "d466b171-fd61-4cbb-9af1-925c3f27df6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model LinearDiscriminantAnalysis()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all sequences: 0.528\n",
      "[[15198     0   864     0     0]\n",
      " [    0 12074  7928    59     0]\n",
      " [    4  2884 27681  2391     0]\n",
      " [    0   846 18523   716     0]\n",
      " [    6  2403 12798  1017     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over sequence 1: 0.481\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3124 2292   23    0]\n",
      " [   1  841 6068  738    0]\n",
      " [   0  423 4948  357    0]\n",
      " [   0  860 3435  345    0]]\n",
      "accuracy over sequence 2: 0.562\n",
      "[[4000    0  864    0    0]\n",
      " [   0 2871 2249    0    0]\n",
      " [   2 1095 9188  659    0]\n",
      " [   0    0 4192    0    0]\n",
      " [   6  526 2697  227    0]]\n",
      "accuracy over sequence 3: 0.596\n",
      "[[4544    0    0    0    0]\n",
      " [   0 2955 1095   13    0]\n",
      " [   0  107 6357  256    0]\n",
      " [   0    0 4435    2    0]\n",
      " [   0  157 3231  100    0]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:976: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  estimator=estimator,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all sequences: 0.737\n",
      "[[15894     0   168     0     0]\n",
      " [    0 10142  1085  8031   803]\n",
      " [    0   105 27879    95  4881]\n",
      " [    0   864   457 18028   736]\n",
      " [    0   188 10173   136  5727]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over sequence 1: 0.72\n",
      "[[3270    0   57    0    0]\n",
      " [   0 2605  262 2291  281]\n",
      " [   0   27 6205   22 1394]\n",
      " [   0  410   26 5044  248]\n",
      " [   0   70 2359   62 2149]]\n",
      "accuracy over sequence 2: 0.743\n",
      "[[4812    0   52    0    0]\n",
      " [   0 2442  545 1984  149]\n",
      " [   0   36 9057   27 1824]\n",
      " [   0   17  107 3965  103]\n",
      " [   0   39 2444    7  966]]\n",
      "accuracy over sequence 3: 0.769\n",
      "[[4542    0    2    0    0]\n",
      " [   0 2490   16 1465   92]\n",
      " [   0   15 6412   24  269]\n",
      " [   0   27  298 3975  137]\n",
      " [   0    9 3011    5  463]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all sequences: 0.556\n",
      "[[15198     0   864     0     0]\n",
      " [    0  5322  2214 10707  1818]\n",
      " [    2   581 14078 10525  7774]\n",
      " [    0    10     3 19086   986]\n",
      " [    1   641  4926  5791  4865]]\n",
      "accuracy over sequence 1: 0.526\n",
      "[[3327    0    0    0    0]\n",
      " [   0  778  834 3281  546]\n",
      " [   1   84 3279 2381 1903]\n",
      " [   0    5    0 5304  419]\n",
      " [   0  244 1391 1619 1386]]\n",
      "accuracy over sequence 2: 0.531\n",
      "[[4000    0  864    0    0]\n",
      " [   0 1733  545 2500  342]\n",
      " [   0  368 4389 3606 2581]\n",
      " [   0    0    0 4132   60]\n",
      " [   1  147 1121 1263  924]]\n",
      "accuracy over sequence 3: 0.655\n",
      "[[4544    0    0    0    0]\n",
      " [   0 2033    1 1645  384]\n",
      " [   0   45 3131 2157 1387]\n",
      " [   0    0    3 4346   88]\n",
      " [   0    6 1023 1290 1169]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.697\n",
      "[[16062     0     0     0     0]\n",
      " [    0 10980  2727  6061   293]\n",
      " [    4    76 28818   229  3833]\n",
      " [    0  2835  3179 13754   317]\n",
      " [    1    84 11973   277  3889]]\n",
      "accuracy over sequence 1: 0.628\n",
      "[[3327    0    0    0    0]\n",
      " [   0 2786  706 1857   90]\n",
      " [   1   23 6617   46  961]\n",
      " [   0 1360 1225 3080   63]\n",
      " [   0   37 3497  102 1004]]\n",
      "accuracy over sequence 2: 0.767\n",
      "[[4864    0    0    0    0]\n",
      " [   0 2363 1190 1484   83]\n",
      " [   0   25 9586   94 1239]\n",
      " [   0    4   74 4087   27]\n",
      " [   1    9 2400   42 1004]]\n",
      "accuracy over sequence 3: 0.773\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3045  125  863   30]\n",
      " [   2    5 5998   43  672]\n",
      " [   0  111  655 3507  164]\n",
      " [   0    1 2579   31  877]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.646\n",
      "[[15198     0   864     0     0]\n",
      " [    0  7845  3567  8572    77]\n",
      " [    0    17 30814   202  1927]\n",
      " [    0  1274  6966 11698   147]\n",
      " [    0    50 13402   247  2525]]\n",
      "accuracy over sequence 1: 0.577\n",
      "[[3327    0    0    0    0]\n",
      " [   0 1903 1137 2375   24]\n",
      " [   0    5 7131   36  476]\n",
      " [   0  637 2558 2492   41]\n",
      " [   0   25 3933   85  597]]\n",
      "accuracy over sequence 2: 0.735\n",
      "[[ 4000     0   864     0     0]\n",
      " [    0  1999   919  2202     0]\n",
      " [    0     7 10223    83   631]\n",
      " [    0     0   139  4046     7]\n",
      " [    0     0  2676    41   739]]\n",
      "accuracy over sequence 3: 0.696\n",
      "[[4544    0    0    0    0]\n",
      " [   0 2040  374 1620   29]\n",
      " [   0    0 6329   47  344]\n",
      " [   0    0 1711 2668   58]\n",
      " [   0    0 2860   36  592]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.698\n",
      "[[16062     0     0     0     0]\n",
      " [    0  8926  1906  9081   148]\n",
      " [    0    18 30372   131  2439]\n",
      " [    0   982  4362 14559   182]\n",
      " [    0    32 12359   195  3638]]\n",
      "accuracy over sequence 1: 0.64\n",
      "[[3327    0    0    0    0]\n",
      " [   0 2246  653 2494   46]\n",
      " [   0    8 7031   21  588]\n",
      " [   0  485 1595 3585   63]\n",
      " [   0   16 3585   79  960]]\n",
      "accuracy over sequence 2: 0.767\n",
      "[[ 4864     0     0     0     0]\n",
      " [    0  2073   579  2440    28]\n",
      " [    0     1 10042    57   844]\n",
      " [    0     0   117  4066     9]\n",
      " [    0     0  2550    22   884]]\n",
      "accuracy over sequence 3: 0.745\n",
      "[[4544    0    0    0    0]\n",
      " [   0 2361   21 1653   28]\n",
      " [   0    1 6268   32  419]\n",
      " [   0   12 1055 3323   47]\n",
      " [   0    0 2639   15  834]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.719\n",
      "[[16062     0     0     0     0]\n",
      " [    0  9040  1322  9583   116]\n",
      " [    0    25 29864   284  2787]\n",
      " [    0  1453  1002 16385  1245]\n",
      " [    0    54 11425   309  4436]]\n",
      "accuracy over sequence 1: 0.668\n",
      "[[3327    0    0    0    0]\n",
      " [   0 2027  376 2990   46]\n",
      " [   0    3 6874   68  703]\n",
      " [   0  726  240 4430  332]\n",
      " [   0   27 3275  118 1220]]\n",
      "accuracy over sequence 2: 0.772\n",
      "[[4864    0    0    0    0]\n",
      " [   0 2219  556 2331   14]\n",
      " [   0   19 9837  104  984]\n",
      " [   0    0   94 4089    9]\n",
      " [   0    0 2354   44 1058]]\n",
      "accuracy over sequence 3: 0.773\n",
      "[[4544    0    0    0    0]\n",
      " [   0 2767   14 1272   10]\n",
      " [   0    0 6279   44  397]\n",
      " [   0    1  428 3436  572]\n",
      " [   0    0 2521   29  938]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all sequences: 0.534\n",
      "[[15198     0   864     0     0]\n",
      " [    0 12942  7119     0     0]\n",
      " [    3  4869 28088     0     0]\n",
      " [    0  2561 17524     0     0]\n",
      " [    1  3527 12696     0     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over sequence 1: 0.485\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3364 2075    0    0]\n",
      " [   1 1357 6290    0    0]\n",
      " [   0 1279 4449    0    0]\n",
      " [   0 1163 3477    0    0]]\n",
      "accuracy over sequence 2: 0.577\n",
      "[[4000    0  864    0    0]\n",
      " [   0 3184 1936    0    0]\n",
      " [   1 1651 9292    0    0]\n",
      " [   0    0 4192    0    0]\n",
      " [   1  746 2709    0    0]]\n",
      "accuracy over sequence 3: 0.593\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3030 1033    0    0]\n",
      " [   0  504 6216    0    0]\n",
      " [   0    3 4434    0    0]\n",
      " [   0  455 3033    0    0]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:566: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  X = check_array(X, **check_params)\n"
     ]
    }
   ],
   "source": [
    "# implement the classifiers\n",
    "classifiers = [\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    AdaBoostClassifier(random_state=100463947), \n",
    "    BaggingClassifier(random_state=100463947), \n",
    "    ExtraTreesClassifier(random_state=100463947),\n",
    "    RandomForestClassifier(random_state=100463947), \n",
    "    HistGradientBoostingClassifier(random_state=100463947),\n",
    "    LinearSVC(random_state=100463947)\n",
    "    ]\n",
    "\n",
    "i=0\n",
    "for clf in classifiers:\n",
    "    print('model',str(clf))\n",
    "    \n",
    "    clf.fit(X,Y.ravel())\n",
    "    pred = clf.predict(X_real_test)\n",
    "    print(\"accuracy over all sequences:\",round(metrics.accuracy_score(Y_real_test,pred),3))\n",
    "    print(metrics.confusion_matrix(Y_real_test, pred))\n",
    "\n",
    "    for k in range(3):\n",
    "      y_test_pred = clf.predict(data_test[k])\n",
    "      print('accuracy over sequence ',k+1,': ',round(metrics.accuracy_score(label_test[k].T, y_test_pred),3),sep='')\n",
    "      print(metrics.confusion_matrix(label_test[k].T, y_test_pred))\n",
    "    \n",
    "    i=i+1\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNpLCvwOlPEd"
   },
   "source": [
    "We have obtained that the **results do not improve**.\n",
    "\n",
    "Possibly because as it's converted to numeric, it confuses the patterns for each sequence.\n",
    "(i.e. sequence 2 is \"twice\" sequence 1)\n",
    "\n",
    "Let's try the next implementation: selecting the best individual model per sequence (with default values),\n",
    "and then predict each observation on test by the majority vote among the 8 individual models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apS2v1ryci12"
   },
   "source": [
    "## 3. One model per sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFsj7en4cjhy"
   },
   "source": [
    "First, we need to select one model per sequence, among the ones that we have been trying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "CB4XOhFWokhJ"
   },
   "outputs": [],
   "source": [
    "# re-load data\n",
    "ar_data = sio.loadmat('AR_database.mat', verify_compressed_data_integrity=False)\n",
    "data_train = ar_data['data_train'][:,0]\n",
    "label_train = ar_data['label_train'][:,0]\n",
    "data_test = ar_data['data_test'][:,0]\n",
    "label_test = ar_data['label_test'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9IZJAQcmIkB",
    "outputId": "7e15f782-f450-4828-b974-847ccf4fb366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence 1\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.549\n",
      "[[13534     0   864  1664     0]\n",
      " [    0 10912  2309  6452   388]\n",
      " [    3  2663 21302  7615  1377]\n",
      " [    0   174  7894 11091   926]\n",
      " [    4  2017  8043  5135  1025]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.717\n",
      "[[15075     0   987     0     0]\n",
      " [    0 12809  1179  5617   456]\n",
      " [    0    66 24511    92  8291]\n",
      " [    0  1402   595 17112   976]\n",
      " [    0   119  9857   224  6024]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.433\n",
      "[[11118     0  4944     0     0]\n",
      " [    0  7438   577   437 11609]\n",
      " [    0  1094 16397  6580  8889]\n",
      " [    0     8    47  4389 15641]\n",
      " [    0   968  6172  2819  6265]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.672\n",
      "[[13514     0    20     0  2528]\n",
      " [    0 11924  2590  4801   746]\n",
      " [   12   293 26422   560  5673]\n",
      " [    0  1717  3195 14515   658]\n",
      " [    7    84 11065   671  4397]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.709\n",
      "[[15198     0   864     0     0]\n",
      " [    0 13301  1740  4943    77]\n",
      " [    0   124 27954   314  4568]\n",
      " [    0  2063  2924 14004  1094]\n",
      " [    0    33 11306   645  4240]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.727\n",
      "[[16060     0     0     0     2]\n",
      " [    2 12632  2588  4758    81]\n",
      " [    2   149 28011   265  4533]\n",
      " [    0  1486  2362 15678   559]\n",
      " [    1    41 11456   476  4250]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.695\n",
      "[[15671     0   391     0     0]\n",
      " [    0 12506  1575  5837   143]\n",
      " [    7   194 26314   317  6128]\n",
      " [    0  1906  3216 13411  1552]\n",
      " [    2    46 10253   623  5300]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.556\n",
      "[[13534     0   544  1984     0]\n",
      " [    0 12524  4405  3132     0]\n",
      " [    5  4209 23619  4874   253]\n",
      " [    0   993 10522  8566     4]\n",
      " [    9  2983  9447  3464   321]]\n",
      "\n",
      "\n",
      "sequence 2\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.541\n",
      "[[15192     0   870     0     0]\n",
      " [    0 13387  3362  3214    98]\n",
      " [    2  4199 25233  3092   434]\n",
      " [    0  3844 13144  3097     0]\n",
      " [    1  3254 10788  2112    69]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.689\n",
      "[[13480     0  2582     0     0]\n",
      " [    0 13330   993  5051   687]\n",
      " [    0    96 22205    30 10629]\n",
      " [    0  2589   400 14780  2316]\n",
      " [    0   199  7115    64  8846]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.555\n",
      "[[13613     0  2449     0     0]\n",
      " [    0  9873  3809  4235  2144]\n",
      " [    4  1727 18706 11875   648]\n",
      " [    0  3416   556 15765   348]\n",
      " [    0  1786  7764  6165   509]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.675\n",
      "[[13613     0  2449     0     0]\n",
      " [    0 13523  1514  4203   821]\n",
      " [    5   234 26268   220  6233]\n",
      " [    0  3356  4184 11480  1065]\n",
      " [    0   186  9531   276  6231]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.712\n",
      "[[15198     0   864     0     0]\n",
      " [    0 13548  1562  4043   908]\n",
      " [    0    71 27200   115  5574]\n",
      " [    0  3306  3750 12474   555]\n",
      " [    0    93  9252   240  6639]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.721\n",
      "[[16062     0     0     0     0]\n",
      " [    0 13660  1264  4800   337]\n",
      " [    3    74 26981    96  5806]\n",
      " [    0  2960  3789 12785   551]\n",
      " [    0    94  9465   164  6501]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.716\n",
      "[[16058     0     4     0     0]\n",
      " [    0 13897  1379  4460   325]\n",
      " [    2   138 25900   147  6773]\n",
      " [    0  3627  3646 12320   492]\n",
      " [    0   177  8569   225  7253]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.528\n",
      "[[14596     0  1466     0     0]\n",
      " [    0 13483  6578     0     0]\n",
      " [    2  5274 27584   100     0]\n",
      " [    0  4368 15717     0     0]\n",
      " [    2  3804 12381    37     0]]\n",
      "\n",
      "\n",
      "sequence 3\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.523\n",
      "[[13534     0  2528     0     0]\n",
      " [    0 14588  1952  3521     0]\n",
      " [    3  4948 23845  4141    23]\n",
      " [    0  4319 12624  3142     0]\n",
      " [    3  4007  9837  2365    12]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.623\n",
      "[[11353     0  4709     0     0]\n",
      " [    0 15562   980  2396  1123]\n",
      " [    0    43 18006    44 14867]\n",
      " [    0  5490    50  8997  5548]\n",
      " [    0    75  4312    80 11757]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.457\n",
      "[[15197     0   865     0     0]\n",
      " [   10     0 20051     0     0]\n",
      " [    1     0 32959     0     0]\n",
      " [    0     0 20085     0     0]\n",
      " [    0     0 16224     0     0]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.644\n",
      "[[12000     0  4062     0     0]\n",
      " [    0 14620  1585  3423   433]\n",
      " [    0   223 26943   159  5635]\n",
      " [    0  3122  3548  8442  4973]\n",
      " [    1   227  9985   118  5893]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.713\n",
      "[[15004     0  1058     0     0]\n",
      " [    0 15237  1268  3267   289]\n",
      " [    0    90 28260    67  4543]\n",
      " [    0  3947  1907 10737  3494]\n",
      " [    0    82 10151    97  5894]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.684\n",
      "[[12016     0  4046     0     0]\n",
      " [    0 15209  1299  3135   418]\n",
      " [    0    85 27944    84  4847]\n",
      " [    0  3864  1021 10532  4668]\n",
      " [    1    64  9731    81  6347]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.668\n",
      "[[12412     0  3650     0     0]\n",
      " [    0 13264  2353  3428  1016]\n",
      " [    6   134 26587    83  6150]\n",
      " [    0  3276  3538 11444  1827]\n",
      " [    2    70  9327    84  6741]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.52\n",
      "[[13534     0  2528     0     0]\n",
      " [    0 15457  4604     0     0]\n",
      " [    3  7147 25805     4     1]\n",
      " [    0  5244 14841     0     0]\n",
      " [    7  4823 11389     0     5]]\n",
      "\n",
      "\n",
      "sequence 4\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.555\n",
      "[[15198     0   864     0     0]\n",
      " [  692 15161  1011  3197     0]\n",
      " [   88  6513 18001  8358     0]\n",
      " [    0  5340  4620 10125     0]\n",
      " [   29  4635  6486  5074     0]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.631\n",
      "[[14034     0  2028     0     0]\n",
      " [    0  7155  3951  5701  3254]\n",
      " [    0   147 23225     3  9585]\n",
      " [    0  4863   119 13610  1493]\n",
      " [    0   214  7489     8  8513]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.536\n",
      "[[13469     0  2593     0     0]\n",
      " [    0  9623  7214  2968   256]\n",
      " [    3  2040 22207  8181   529]\n",
      " [    0  7996  1002 10803   284]\n",
      " [    3  1285 10317  4195   424]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.671\n",
      "[[16018     0    44     0     0]\n",
      " [    0 13242  5229  1117   473]\n",
      " [    7   188 26297   114  6354]\n",
      " [    0  6859  3416  9063   747]\n",
      " [    3   162  9853   126  6080]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.675\n",
      "[[15198     0   864     0     0]\n",
      " [    0 11598  7076   870   517]\n",
      " [    0    61 27411    58  5430]\n",
      " [    0  6944  1636 10710   795]\n",
      " [    0    89  9759   147  6229]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.684\n",
      "[[16058     0     4     0     0]\n",
      " [    0 13110  5306  1259   386]\n",
      " [    0    88 26989    44  5839]\n",
      " [    0  7010  2692  9451   932]\n",
      " [    0   117  9517   101  6489]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.683\n",
      "[[16062     0     0     0     0]\n",
      " [    0 12807  5692  1226   336]\n",
      " [    8   201 25243    63  7445]\n",
      " [    0  7225  1646 10408   806]\n",
      " [    7   252  8347   125  7493]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.532\n",
      "[[15198     0   864     0     0]\n",
      " [ 2150 11190  1020  5701     0]\n",
      " [  160  4962 19887  7951     0]\n",
      " [    0  3967  6277  9841     0]\n",
      " [   32  3573  7319  5300     0]]\n",
      "\n",
      "\n",
      "sequence 5\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.516\n",
      "[[13534     0   864  1664     0]\n",
      " [    0 15518     0  4543     0]\n",
      " [    0  6622 10198 15768   372]\n",
      " [    0  4554   559 14972     0]\n",
      " [    0  4989  2525  8581   129]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.55\n",
      "[[ 8869     0  7193     0     0]\n",
      " [    0 14340  1741  2345  1635]\n",
      " [    0    59 16316    44 16541]\n",
      " [    0  6785    57  7109  6134]\n",
      " [    0    68  4769    87 11300]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.4\n",
      "[[12469     0  3593     0     0]\n",
      " [    0  6678  8686  2096  2601]\n",
      " [    2   747  9739  9019 13453]\n",
      " [    0     2  9856  8090  2137]\n",
      " [    0   581  6114  4366  5163]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.658\n",
      "[[12859     0  3203     0     0]\n",
      " [    0 15724   846  2500   991]\n",
      " [    1   554 22097   600  9708]\n",
      " [    0  6236  2312 10824   713]\n",
      " [    0   331  7519   537  7837]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.66\n",
      "[[12510     0  3552     0     0]\n",
      " [    0 13015   780  3369  2897]\n",
      " [    0   160 22144   343 10313]\n",
      " [    0  1909   842 12890  4444]\n",
      " [    0   124  6623   485  8992]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.684\n",
      "[[12736  2035  1175     0   116]\n",
      " [    0 15688   576  2657  1140]\n",
      " [    0   234 22348   335 10043]\n",
      " [    0  5888   930 12501   766]\n",
      " [    0   144  6918   367  8795]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.657\n",
      "[[11552     0  2920     0  1590]\n",
      " [    0 15779   159  2718  1405]\n",
      " [    0   209 21462   362 10927]\n",
      " [    0  6175   874 11710  1326]\n",
      " [    0   167  6890   468  8699]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.517\n",
      "[[13556  1598   532   376     0]\n",
      " [    0 16288     0  3773     0]\n",
      " [    2  8419 12560 11933    46]\n",
      " [    0  6415  1576 12094     0]\n",
      " [    0  5692  3283  7246     3]]\n",
      "\n",
      "\n",
      "sequence 6\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.527\n",
      "[[15198     0   864     0     0]\n",
      " [    0 11825  8062   174     0]\n",
      " [    3  2741 27633  2361   222]\n",
      " [    0   214 19022   849     0]\n",
      " [    5  2333 12688  1195     3]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.708\n",
      "[[15079     0   983     0     0]\n",
      " [    0  9990  2362  7051   658]\n",
      " [    0    19 30015   142  2784]\n",
      " [    0  1121  1420 16968   576]\n",
      " [    0    36 13521   141  2526]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.457\n",
      "[[15198     0   864     0     0]\n",
      " [   20     0 20041     0     0]\n",
      " [    9     0 32951     0     0]\n",
      " [    0     0 20085     0     0]\n",
      " [    2     0 16222     0     0]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.658\n",
      "[[16033     1    28     0     0]\n",
      " [    0 11738  3233  4838   252]\n",
      " [    4   128 26221   375  6232]\n",
      " [    0  1540  7529 10723   293]\n",
      " [    1    72 11208   272  4671]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.668\n",
      "[[15198     0   864     0     0]\n",
      " [    0 11869  2064  5333   795]\n",
      " [    0    56 27881   243  4780]\n",
      " [    0  1487  6225 11671   702]\n",
      " [    0    33 12177   228  3786]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.706\n",
      "[[16051     0    11     0     0]\n",
      " [    0 11150  1682  7097   132]\n",
      " [    1    39 27846   181  4893]\n",
      " [    0   978  3741 15169   197]\n",
      " [    1    30 11889   163  4141]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.709\n",
      "[[16061     0     1     0     0]\n",
      " [    2 11551  1447  6596   465]\n",
      " [    5    73 25564   311  7007]\n",
      " [    0  1361  1529 16301   894]\n",
      " [    0    41 10678   276  5229]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.531\n",
      "[[15192     0   870     0     0]\n",
      " [    0 12842  7219     0     0]\n",
      " [    6  4945 27929    79     1]\n",
      " [    0  1057 19028     0     0]\n",
      " [    8  3658 12534    21     3]]\n",
      "\n",
      "\n",
      "sequence 7\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.492\n",
      "[[15608     0     0   454     0]\n",
      " [    0  9535  8001  2525     0]\n",
      " [   44  2921 20449  9360   186]\n",
      " [    0   154 13650  6281     0]\n",
      " [   14  2309  8474  5407    20]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.656\n",
      "[[14409     0  1653     0     0]\n",
      " [    0 14469  2074  2112  1406]\n",
      " [    0    36 22768    19 10137]\n",
      " [    0  5457   210  9251  5167]\n",
      " [    0    51  7912    36  8225]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.372\n",
      "[[ 6247  9813     2     0     0]\n",
      " [    0     0 20061     0     0]\n",
      " [    0     8 32952     0     0]\n",
      " [    0     0 20085     0     0]\n",
      " [    0     1 16223     0     0]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.621\n",
      "[[15057   922    83     0     0]\n",
      " [    0  9302  4117  3385  3257]\n",
      " [    8    52 25895   157  6848]\n",
      " [    0  3415  4543  9416  2711]\n",
      " [    1    26 10225   196  5776]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.628\n",
      "[[15198     0   864     0     0]\n",
      " [    0  9249  4455  3802  2555]\n",
      " [    0     8 26836   123  5993]\n",
      " [    0  2616  6084  9041  2344]\n",
      " [    0     4 10198   188  5834]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.673\n",
      "[[15142   920     0     0     0]\n",
      " [    0 12526  2362  3203  1970]\n",
      " [    3     8 26778   100  6071]\n",
      " [    0  2680  2778 10286  4341]\n",
      " [    0     3  9879   145  6197]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.667\n",
      "[[16061     0     1     0     0]\n",
      " [  146 12014  2499  3821  1581]\n",
      " [    4     7 25513   156  7280]\n",
      " [    0  1709  3474  9901  5001]\n",
      " [    1     5  9199   225  6794]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.514\n",
      "[[15198     0     0   864     0]\n",
      " [    0 12765  4691  2605     0]\n",
      " [   76  4240 19621  9023     0]\n",
      " [    0  1878 11668  6539     0]\n",
      " [   18  3205  7779  5222     0]]\n",
      "\n",
      "\n",
      "sequence 8\n",
      "model LinearDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.486\n",
      "[[13534     0  2528     0     0]\n",
      " [    0  7722 11100  1239     0]\n",
      " [   30  1777 29182  1971     0]\n",
      " [    0     2 19329   754     0]\n",
      " [   20   835 13542  1827     0]]\n",
      "\n",
      "\n",
      "model QuadraticDiscriminantAnalysis()\n",
      "accuracy over all sequences: 0.595\n",
      "[[12911     0  3151     0     0]\n",
      " [    0 12461  2811  4060   729]\n",
      " [    0    44 30277    32  2607]\n",
      " [    0 13096  2429  3698   862]\n",
      " [    0    91 12754    23  3356]]\n",
      "\n",
      "\n",
      "model AdaBoostClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.478\n",
      "[[14848  1204    10     0     0]\n",
      " [    0  6137 13924     0     0]\n",
      " [    2  2682 29107  1169     0]\n",
      " [    0   750 19102   233     0]\n",
      " [    0  1450 14225   549     0]]\n",
      "\n",
      "\n",
      "model BaggingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.622\n",
      "[[14858  1170    34     0     0]\n",
      " [    0  6086  4871  8602   502]\n",
      " [    8    88 29491   251  3122]\n",
      " [    0   925  6925 12133   102]\n",
      " [    1    97 12805   283  3038]]\n",
      "\n",
      "\n",
      "model ExtraTreesClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.631\n",
      "[[15122     0   940     0     0]\n",
      " [    0  6546  4723  8744    48]\n",
      " [    0    20 30940   203  1797]\n",
      " [    0  1411  6881 11619   174]\n",
      " [    0    61 13668   253  2242]]\n",
      "\n",
      "\n",
      "model RandomForestClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.628\n",
      "[[14790  1031   241     0     0]\n",
      " [  954  5475  4461  9125    46]\n",
      " [   20    28 30607   147  2158]\n",
      " [    0  2329  3546 12811  1399]\n",
      " [    4    50 13475   229  2466]]\n",
      "\n",
      "\n",
      "model HistGradientBoostingClassifier(random_state=100463947)\n",
      "accuracy over all sequences: 0.615\n",
      "[[15016     6  1036     0     4]\n",
      " [ 1650  5257  4264  8495   395]\n",
      " [   31    32 29277   197  3423]\n",
      " [    0  1612  5478 11526  1469]\n",
      " [    4    36 12200   265  3719]]\n",
      "\n",
      "\n",
      "model LinearSVC(random_state=100463947)\n",
      "accuracy over all sequences: 0.471\n",
      "[[13534     0  2528     0     0]\n",
      " [    0  6468 10759  2834     0]\n",
      " [   40  1989 29599  1332     0]\n",
      " [    0    72 19923    90     0]\n",
      " [   13  1524 13475  1212     0]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try every model on its own for each sequence\n",
    "classifiers = [\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    AdaBoostClassifier(random_state=100463947), \n",
    "    BaggingClassifier(random_state=100463947), \n",
    "    ExtraTreesClassifier(random_state=100463947),\n",
    "    RandomForestClassifier(random_state=100463947), \n",
    "    HistGradientBoostingClassifier(random_state=100463947),\n",
    "    LinearSVC(random_state=100463947)\n",
    "    ]\n",
    "\n",
    "X_real_test = data_test[0].T\n",
    "Y_real_test = label_test[0].T\n",
    "for k in range(3):\n",
    "  X_real_test = np.concatenate((X_real_test,data_test[k].T))\n",
    "  Y_real_test = np.concatenate((Y_real_test,label_test[k].T))   \n",
    "\n",
    "for j in range(8):\n",
    "  print('sequence',j+1)\n",
    "  X = data_train[j].T\n",
    "  Y = label_train[j].T\n",
    "\n",
    "  for clf in classifiers:\n",
    "      print('model',str(clf))\n",
    "      \n",
    "      clf.fit(X,Y.ravel())\n",
    "      pred = clf.predict(X_real_test)\n",
    "      print(\"accuracy over all sequences:\",round(metrics.accuracy_score(Y_real_test,pred),3))\n",
    "      print(metrics.confusion_matrix(Y_real_test, pred))\n",
    "      print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byH0IlWkruxL"
   },
   "source": [
    "Best performing model per sequence:\n",
    "\n",
    "- Seq 1: Random Forest\n",
    "\n",
    "- Seq 2: Random Forest\n",
    "\n",
    "- Seq 3: Extra Trees\n",
    "\n",
    "- Seq 4: Random Forest\n",
    "\n",
    "- Seq 5: Random Forest\n",
    "\n",
    "- Seq 6: Hist Gradient Boosting\n",
    "\n",
    "- Seq 7: Random Forest\n",
    "\n",
    "- Seq 8: Extra Trees\n",
    "\n",
    "Now, we will re-train the best model for each sequence, and predict based on the majority class among all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xXb72YuotCyf"
   },
   "outputs": [],
   "source": [
    "# train one model per sequence\n",
    "X = data_train[0].T\n",
    "Y = label_train[0].T\n",
    "mod1 = RandomForestClassifier(random_state=100463947).fit(X,Y.ravel())\n",
    "\n",
    "X = data_train[1].T\n",
    "Y = label_train[1].T\n",
    "mod2 = RandomForestClassifier(random_state=100463947).fit(X,Y.ravel())\n",
    "\n",
    "X = data_train[2].T\n",
    "Y = label_train[2].T\n",
    "mod3 = ExtraTreesClassifier(random_state=100463947).fit(X,Y.ravel())\n",
    "\n",
    "X = data_train[3].T\n",
    "Y = label_train[3].T\n",
    "mod4 = RandomForestClassifier(random_state=100463947).fit(X,Y.ravel())\n",
    "\n",
    "X = data_train[4].T\n",
    "Y = label_train[4].T\n",
    "mod5 = RandomForestClassifier(random_state=100463947).fit(X,Y.ravel())\n",
    "\n",
    "X = data_train[5].T\n",
    "Y = label_train[5].T\n",
    "mod6 = HistGradientBoostingClassifier(random_state=100463947).fit(X,Y.ravel())\n",
    "\n",
    "X = data_train[6].T\n",
    "Y = label_train[6].T\n",
    "mod7 = RandomForestClassifier(random_state=100463947).fit(X,Y.ravel())\n",
    "\n",
    "X = data_train[7].T\n",
    "Y = label_train[7].T\n",
    "mod8 = ExtraTreesClassifier(random_state=100463947).fit(X,Y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NhWQt0-XtCtb"
   },
   "outputs": [],
   "source": [
    "X_real_test = data_test[0].T\n",
    "Y_real_test = label_test[0].T\n",
    "for k in range(3):\n",
    "  X_real_test = np.concatenate((X_real_test,data_test[k].T))\n",
    "  Y_real_test = np.concatenate((Y_real_test,label_test[k].T))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85QlBlertCp6",
    "outputId": "62f1591b-1253-40da-aab3-1645df9726c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "# this takes quite a long time (a couple of hours), counter printed for reference\n",
    "final_preds = list()\n",
    "for j in range(X_real_test.shape[0]):\n",
    "  if j%20000 == 0:\n",
    "    print(j)\n",
    "  obs = X_real_test[j,:]\n",
    "  p1 = mod1.predict(obs.reshape(1,-1))\n",
    "  p2 = mod2.predict(obs.reshape(1,-1))\n",
    "  p3 = mod3.predict(obs.reshape(1,-1))\n",
    "  p4 = mod4.predict(obs.reshape(1,-1))\n",
    "  p5 = mod5.predict(obs.reshape(1,-1))\n",
    "  p6 = mod6.predict(obs.reshape(1,-1))\n",
    "  p7 = mod7.predict(obs.reshape(1,-1))\n",
    "  p8 = mod8.predict(obs.reshape(1,-1))\n",
    "  lst = [p1[0],p2[0],p3[0],p4[0],p5[0],p6[0],p7[0],p8[0]]\n",
    "  most_repeated = max(set(lst), key=lst.count)\n",
    "  final_preds.append(most_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfiHhImmwyNc",
    "outputId": "db52da86-efcd-4006-b627-deae31a6400b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy over all sequences: 0.744\n",
      "[[16062     0     0     0     0]\n",
      " [    0 15093  1383  3447   138]\n",
      " [    0    43 30911    92  1914]\n",
      " [    0  4156  2950 12658   321]\n",
      " [    0    63 12374   149  3638]]\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy over all sequences:\",round(metrics.accuracy_score(Y_real_test,final_preds),3))\n",
    "print(metrics.confusion_matrix(Y_real_test, final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mhmdn3wjLuI"
   },
   "source": [
    "This model achieves a **0.744 accuracy** over the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsPmBVh-inLK",
    "outputId": "398cc673-f616-42dd-9ae5-c26f8edb0acf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "10000\n",
      "20000\n",
      "accuracy over sequence 1: 0.669\n",
      "[[3327    0    0    0    0]\n",
      " [   0 3831  394 1173   41]\n",
      " [   0   11 7170   14  453]\n",
      " [   0 2073  874 2651  130]\n",
      " [   0   29 3602   67  942]]\n",
      "1\n",
      "0\n",
      "10000\n",
      "20000\n",
      "accuracy over sequence 2: 0.835\n",
      "[[ 4864     0     0     0     0]\n",
      " [    0  3977   553   554    36]\n",
      " [    0    18 10172    44   710]\n",
      " [    0     0   127  4035    30]\n",
      " [    0     2  2646     9   799]]\n",
      "2\n",
      "0\n",
      "10000\n",
      "20000\n",
      "accuracy over sequence 3: 0.803\n",
      "[[4544    0    0    0    0]\n",
      " [   0 3454   42  547   20]\n",
      " [   0    3 6399   20  298]\n",
      " [   0   10 1075 3321   31]\n",
      " [   0    3 2524    6  955]]\n"
     ]
    }
   ],
   "source": [
    "# now, predict for every sequence\n",
    "for k in range(3):\n",
    "  print(k)\n",
    "  final_preds = list()\n",
    "  for j in range(data_test[k].shape[1]):\n",
    "    if j%10000 == 0:\n",
    "      print(j)\n",
    "    obs = data_test[k][:,j].T\n",
    "    p1 = mod1.predict(obs.reshape(1,-1))\n",
    "    p2 = mod2.predict(obs.reshape(1,-1))\n",
    "    p3 = mod3.predict(obs.reshape(1,-1))\n",
    "    p4 = mod4.predict(obs.reshape(1,-1))\n",
    "    p5 = mod5.predict(obs.reshape(1,-1))\n",
    "    p6 = mod6.predict(obs.reshape(1,-1))\n",
    "    p7 = mod7.predict(obs.reshape(1,-1))\n",
    "    p8 = mod8.predict(obs.reshape(1,-1))\n",
    "    lst = [p1[0],p2[0],p3[0],p4[0],p5[0],p6[0],p7[0],p8[0]]\n",
    "    most_repeated = max(set(lst), key=lst.count)\n",
    "    final_preds.append(most_repeated)\n",
    "  print('accuracy over sequence ',k+1,': ',round(metrics.accuracy_score(label_test[k].T, final_preds),3),sep='')\n",
    "  print(metrics.confusion_matrix(label_test[k].T, final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFdFnyaCaTWl"
   },
   "source": [
    "The accuracies evaluated on every test sequence are **0.669, 0.835, 0.803**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVzSC4X5pMaR"
   },
   "source": [
    "# Part 2. MFCC variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SBSIJwtpMXd"
   },
   "source": [
    "Now we will try to predict using the variables provided by the MFCC.\n",
    "\n",
    "We will not be including 'id' variable and not doing one model per sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O4CRJ_hGJzTw"
   },
   "outputs": [],
   "source": [
    "# re-load data\n",
    "import librosa\n",
    "\n",
    "data_train = ar_data['data_train'][:,0]\n",
    "label_train = ar_data['label_train'][:,0]\n",
    "data_test = ar_data['data_test'][:,0]\n",
    "label_test = ar_data['label_test'][:,0]\n",
    "\n",
    "sr = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "M1cnBRYJqtpw"
   },
   "outputs": [],
   "source": [
    "X = data_train[0].T\n",
    "Y = label_train[0].T\n",
    "\n",
    "for k in range(1,8):\n",
    "  X = np.concatenate((X,data_train[k].T))\n",
    "  Y = np.concatenate((Y,label_train[k].T))\n",
    "\n",
    "X_real_test = data_test[0].T\n",
    "Y_real_test = label_test[0].T\n",
    "for k in range(3):\n",
    "  X_real_test = np.concatenate((X_real_test,data_test[k].T))\n",
    "  Y_real_test = np.concatenate((Y_real_test,label_test[k].T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fRptjT1t-z2"
   },
   "source": [
    "## 1. Gaussian Mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAmXw-Hluz_V"
   },
   "outputs": [],
   "source": [
    "# convert datasets to dataframes for ease in implementation\n",
    "merge_train = np.append(X,Y,axis=1)\n",
    "merge_test = np.append(X_real_test,Y_real_test,axis=1)\n",
    "merge_train = pd.DataFrame(merge_train, columns = ['x1','y1','z1','x2','y2','z2','label'])\n",
    "merge_test = pd.DataFrame(merge_test, columns = ['x1','y1','z1','x2','y2','z2','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o487QEJju6cW"
   },
   "outputs": [],
   "source": [
    "# train one model per label\n",
    "classes = np.unique(Y)\n",
    "nclasses = len(classes)\n",
    "\n",
    "models = []\n",
    "for i in range(nclasses):\n",
    "  mfcc_train = []\n",
    "  data_train_class = merge_train.loc[merge_train['label'] == classes[i], ['x1','y1','z1','x2','y2','z2']]\n",
    "  for j in range(6):\n",
    "    y = data_train_class.iloc[:,j]\n",
    "    y = y.to_numpy()\n",
    "    mfcc = librosa.feature.mfcc(y, sr, n_mfcc = 100, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "    mfcc_train.append(mfcc.T)\n",
    "\n",
    "  mfcc_train = np.vstack(mfcc_train)\n",
    "  gm = GaussianMixture(n_components=8, \n",
    "                        covariance_type='diag',\n",
    "                        random_state=100463947).fit(mfcc_train)\n",
    "  models.append(gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mqKkdRAu6cW",
    "outputId": "5905af63-d59c-4bb0-c253-6b7a75db0bfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25296, 20)\n",
      "accuracy score: 0.45\n",
      "confusion matrix: \n",
      " [[1666 1228   62  827   57]\n",
      " [1657 1671   77 1362   57]\n",
      " [  57  107 4285   72 3381]\n",
      " [1480 1397  168 1673  118]\n",
      " [  24   53 1645   33 2139]]\n"
     ]
    }
   ],
   "source": [
    "# predict based on highest loglike score\n",
    "scores = []\n",
    "mfcc_test = []\n",
    "for j in range(6):\n",
    "  y = X_real_test[:,j]\n",
    "  mfcc = librosa.feature.mfcc(y, sr, n_mfcc = 100, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "  mfcc_test.append(mfcc.T)\n",
    "\n",
    "mfcc_test = np.vstack(mfcc_test)\n",
    "print(mfcc_test.shape)\n",
    "\n",
    "for gmm in models:\n",
    "  loglike = gmm.score_samples(mfcc_test)\n",
    "  scores.append(loglike)\n",
    "pred_level = np.argmax(scores, axis=0)+1\n",
    "\n",
    "# need to select the appropriate labels to compare (the most repeated one for every 25 samples in the original signal)\n",
    "# pred_level has each feature stacked on top of each other, so get labels and repeat sequence 6 times\n",
    "j=0\n",
    "new_labels = []\n",
    "while j <= len(Y_real_test):\n",
    "  m = stats.mode(Y_real_test[j:j+24].ravel())[0]\n",
    "  new_labels.append(m)\n",
    "  j=j+25\n",
    "\n",
    "new_labels = new_labels*6\n",
    "\n",
    "print('accuracy score:',np.round(accuracy_score(new_labels,pred_level),2)) # 0.45\n",
    "print('confusion matrix:','\\n',confusion_matrix(new_labels,pred_level))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sw4VdIqW-7KP"
   },
   "source": [
    "The accuracy score is much worse than before using this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvT08INP-7IB"
   },
   "source": [
    "## 2. Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQemXIOyJzHe",
    "outputId": "c0eb57f8-dd6b-47df-e02f-83d237270bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.508\n",
      "[[1687  906  138 1104    5]\n",
      " [1601 1246  166 1805    6]\n",
      " [  35    2 6937   53  875]\n",
      " [1364  953  254 2253   12]\n",
      " [  20    5 3128   20  721]]\n",
      "10\n",
      "0.531\n",
      "[[1909  778  114 1025   14]\n",
      " [1662 1205  147 1803    7]\n",
      " [  26    3 6984   55  834]\n",
      " [1315  932  246 2323   20]\n",
      " [  16    1 2852   23 1002]]\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.497\n",
      "[[1822  872   57  998   91]\n",
      " [1589 1293   68 1781   93]\n",
      " [  12    2 4489   32 3367]\n",
      " [1261  931  146 2347  151]\n",
      " [  11    1 1246   17 2619]]\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n",
      "[[1853  820   50 1020   97]\n",
      " [1534 1278   67 1853   92]\n",
      " [  11    1 4616   32 3242]\n",
      " [1241  931  144 2370  150]\n",
      " [  12    1 1238   14 2629]]\n",
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n",
      "[[1853  820   50 1020   97]\n",
      " [1534 1278   67 1853   92]\n",
      " [  11    1 4616   32 3242]\n",
      " [1241  931  144 2370  150]\n",
      " [  12    1 1238   14 2629]]\n",
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n",
      "[[1853  820   50 1020   97]\n",
      " [1534 1278   67 1853   92]\n",
      " [  11    1 4616   32 3242]\n",
      " [1241  931  144 2370  150]\n",
      " [  12    1 1238   14 2629]]\n",
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n",
      "[[1853  820   50 1020   97]\n",
      " [1534 1278   67 1853   92]\n",
      " [  11    1 4616   32 3242]\n",
      " [1241  931  144 2370  150]\n",
      " [  12    1 1238   14 2629]]\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n",
      "[[1853  820   50 1020   97]\n",
      " [1534 1278   67 1853   92]\n",
      " [  11    1 4616   32 3242]\n",
      " [1241  931  144 2370  150]\n",
      " [  12    1 1238   14 2629]]\n",
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.504\n",
      "[[1853  820   50 1020   97]\n",
      " [1534 1278   67 1853   92]\n",
      " [  11    1 4616   32 3242]\n",
      " [1241  931  144 2370  150]\n",
      " [  12    1 1238   14 2629]]\n"
     ]
    }
   ],
   "source": [
    "# ensemble of best models trying number of MFCC = 5,10,...,45\n",
    "\n",
    "# ensemble with soft voting\n",
    "classifiers = [\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    BaggingClassifier(random_state=100463947), \n",
    "    GradientBoostingClassifier(random_state=100463947), \n",
    "    RandomForestClassifier(random_state=100463947), \n",
    "    HistGradientBoostingClassifier(random_state=100463947)\n",
    "    ]\n",
    "initials = ['QDA','Bagg','GB','RF','HGB']\n",
    "\n",
    "e_list = [(i,c) for i,c in zip(initials,classifiers)]\n",
    "\n",
    "j=0\n",
    "new_labels_train = []\n",
    "while j <= Y.shape[0]:\n",
    "  m = stats.mode(Y[j:j+24].ravel())[0]\n",
    "  new_labels_train.append(m)\n",
    "  j=j+25\n",
    "\n",
    "new_labels_train = new_labels_train*6\n",
    "for k in range(5,50,5):\n",
    "  print(k)\n",
    "  mfcc_train = []\n",
    "  for j in range(6):\n",
    "    y = X[:,j]\n",
    "    mfcc = librosa.feature.mfcc(y, sr, n_mfcc = k, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "    mfcc_train.append(mfcc.T)\n",
    "\n",
    "  mfcc_train = np.vstack(mfcc_train)\n",
    "  mfcc_test = []\n",
    "  for j in range(6):\n",
    "    y = X_real_test[:,j]\n",
    "    mfcc = librosa.feature.mfcc(y, sr, n_mfcc = k, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "    mfcc_test.append(mfcc.T)\n",
    "  \n",
    "  mfcc_test = np.vstack(mfcc_test)\n",
    "\n",
    "\n",
    "  j=0\n",
    "  new_labels_test = []\n",
    "  while j <= len(Y_real_test):\n",
    "    m = stats.mode(Y_real_test[j:j+24].ravel())[0]\n",
    "    new_labels_test.append(m)\n",
    "    j=j+25\n",
    "  new_labels_test = new_labels_test*6\n",
    "  \n",
    "  eclf = VotingClassifier(estimators=e_list, voting='soft')\n",
    "  eclf.fit(mfcc_train,np.array(new_labels_train).ravel())\n",
    "  pred = eclf.predict(mfcc_test)\n",
    "  score = round(metrics.accuracy_score(new_labels_test, pred),3)\n",
    "  print(score) # 0.502\n",
    "  print(metrics.confusion_matrix(new_labels_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-t9MxcL1iEIz"
   },
   "source": [
    "The best accuracy is obtained using **10 MFCC, 0.531 accuracy**.\n",
    "\n",
    "Overall, the rest of the models achieve around 0.5 accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCgMhR0Zrewf"
   },
   "source": [
    "## 3. Selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoZM7gYTdu9S"
   },
   "source": [
    "The final implementation we will try is to predict not using the MFCC related to every signal, but to a few of them.\n",
    "\n",
    "In particular, we will try all possible combinations of grouping the numbers 1,...,6 (6 variables) in groups of 1,2,...,6, which is a total of 63 models.\n",
    "\n",
    "For instance, for the combination (1,5), we will select the first and fifth variables in the original dataset, get their respective MFCC, and train the classifier and GMM with these coefficients.\n",
    "\n",
    "We will only evaluate the performance on the entire test set for matters of extensiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1bYRY0Vepim"
   },
   "source": [
    "### 3.1. Gaussian Mixture model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFkjblRSepiu"
   },
   "outputs": [],
   "source": [
    "# convert datasets to dataframes for ease in implementation\n",
    "merge_train = np.append(X,Y,axis=1)\n",
    "merge_test = np.append(X_real_test,Y_real_test,axis=1)\n",
    "merge_train = pd.DataFrame(merge_train, columns = ['x1','y1','z1','x2','y2','z2','label'])\n",
    "merge_test = pd.DataFrame(merge_test, columns = ['x1','y1','z1','x2','y2','z2','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMXt9xibfBki",
    "outputId": "460a5836-0458-4cc3-f760-e95f5f1eb625"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,),\n",
       " (1,),\n",
       " (2,),\n",
       " (3,),\n",
       " (4,),\n",
       " (5,),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (4, 5),\n",
       " (0, 1, 2),\n",
       " (0, 1, 3),\n",
       " (0, 1, 4),\n",
       " (0, 1, 5),\n",
       " (0, 2, 3),\n",
       " (0, 2, 4),\n",
       " (0, 2, 5),\n",
       " (0, 3, 4),\n",
       " (0, 3, 5),\n",
       " (0, 4, 5),\n",
       " (1, 2, 3),\n",
       " (1, 2, 4),\n",
       " (1, 2, 5),\n",
       " (1, 3, 4),\n",
       " (1, 3, 5),\n",
       " (1, 4, 5),\n",
       " (2, 3, 4),\n",
       " (2, 3, 5),\n",
       " (2, 4, 5),\n",
       " (3, 4, 5),\n",
       " (0, 1, 2, 3),\n",
       " (0, 1, 2, 4),\n",
       " (0, 1, 2, 5),\n",
       " (0, 1, 3, 4),\n",
       " (0, 1, 3, 5),\n",
       " (0, 1, 4, 5),\n",
       " (0, 2, 3, 4),\n",
       " (0, 2, 3, 5),\n",
       " (0, 2, 4, 5),\n",
       " (0, 3, 4, 5),\n",
       " (1, 2, 3, 4),\n",
       " (1, 2, 3, 5),\n",
       " (1, 2, 4, 5),\n",
       " (1, 3, 4, 5),\n",
       " (2, 3, 4, 5),\n",
       " (0, 1, 2, 3, 4),\n",
       " (0, 1, 2, 3, 5),\n",
       " (0, 1, 2, 4, 5),\n",
       " (0, 1, 3, 4, 5),\n",
       " (0, 2, 3, 4, 5),\n",
       " (1, 2, 3, 4, 5),\n",
       " (0, 1, 2, 3, 4, 5)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "[com for sub in range(6) for com in combinations([0,1,2,3,4,5], sub + 1)] # all possible combinations of idx variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV_yvG6wepiu",
    "outputId": "ad1f35ed-423b-487e-fd4c-2d085aef7d15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model using variables with idx (0,)\n",
      "accuracy score: 0.64 \n",
      "\n",
      "model using variables with idx (1,)\n",
      "accuracy score: 0.58 \n",
      "\n",
      "model using variables with idx (2,)\n",
      "accuracy score: 0.55 \n",
      "\n",
      "model using variables with idx (3,)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (4,)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (5,)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (0, 1)\n",
      "accuracy score: 0.47 \n",
      "\n",
      "model using variables with idx (0, 2)\n",
      "accuracy score: 0.47 \n",
      "\n",
      "model using variables with idx (0, 3)\n",
      "accuracy score: 0.55 \n",
      "\n",
      "model using variables with idx (0, 4)\n",
      "accuracy score: 0.53 \n",
      "\n",
      "model using variables with idx (0, 5)\n",
      "accuracy score: 0.55 \n",
      "\n",
      "model using variables with idx (1, 2)\n",
      "accuracy score: 0.56 \n",
      "\n",
      "model using variables with idx (1, 3)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (1, 4)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (1, 5)\n",
      "accuracy score: 0.52 \n",
      "\n",
      "model using variables with idx (2, 3)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (2, 4)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (2, 5)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (3, 4)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (3, 5)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (4, 5)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (0, 1, 2)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (0, 1, 3)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 1, 4)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 1, 5)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (0, 2, 3)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 2, 4)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 2, 5)\n",
      "accuracy score: 0.47 \n",
      "\n",
      "model using variables with idx (0, 3, 4)\n",
      "accuracy score: 0.51 \n",
      "\n",
      "model using variables with idx (0, 3, 5)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (0, 4, 5)\n",
      "accuracy score: 0.51 \n",
      "\n",
      "model using variables with idx (1, 2, 3)\n",
      "accuracy score: 0.51 \n",
      "\n",
      "model using variables with idx (1, 2, 4)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (1, 2, 5)\n",
      "accuracy score: 0.53 \n",
      "\n",
      "model using variables with idx (1, 3, 4)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (1, 3, 5)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (1, 4, 5)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (2, 3, 4)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (2, 3, 5)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (2, 4, 5)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (3, 4, 5)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (0, 1, 2, 3)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 1, 2, 4)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 1, 2, 5)\n",
      "accuracy score: 0.47 \n",
      "\n",
      "model using variables with idx (0, 1, 3, 4)\n",
      "accuracy score: 0.45 \n",
      "\n",
      "model using variables with idx (0, 1, 3, 5)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 1, 4, 5)\n",
      "accuracy score: 0.47 \n",
      "\n",
      "model using variables with idx (0, 2, 3, 4)\n",
      "accuracy score: 0.45 \n",
      "\n",
      "model using variables with idx (0, 2, 3, 5)\n",
      "accuracy score: 0.45 \n",
      "\n",
      "model using variables with idx (0, 2, 4, 5)\n",
      "accuracy score: 0.47 \n",
      "\n",
      "model using variables with idx (0, 3, 4, 5)\n",
      "accuracy score: 0.5 \n",
      "\n",
      "model using variables with idx (1, 2, 3, 4)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (1, 2, 3, 5)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (1, 2, 4, 5)\n",
      "accuracy score: 0.49 \n",
      "\n",
      "model using variables with idx (1, 3, 4, 5)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (2, 3, 4, 5)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 1, 2, 3, 4)\n",
      "accuracy score: 0.45 \n",
      "\n",
      "model using variables with idx (0, 1, 2, 3, 5)\n",
      "accuracy score: 0.45 \n",
      "\n",
      "model using variables with idx (0, 1, 2, 4, 5)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (0, 1, 3, 4, 5)\n",
      "accuracy score: 0.47 \n",
      "\n",
      "model using variables with idx (0, 2, 3, 4, 5)\n",
      "accuracy score: 0.46 \n",
      "\n",
      "model using variables with idx (1, 2, 3, 4, 5)\n",
      "accuracy score: 0.48 \n",
      "\n",
      "model using variables with idx (0, 1, 2, 3, 4, 5)\n",
      "accuracy score: 0.45 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "comb_lst = [com for sub in range(6) for com in combinations([0,1,2,3,4,5], sub + 1)]\n",
    "\n",
    "for comb in comb_lst:\n",
    "  print('model using variables with idx', comb)\n",
    "  # train one model per label\n",
    "  classes = np.unique(Y)\n",
    "  nclasses = len(classes)\n",
    "\n",
    "  models = []\n",
    "  for i in range(nclasses):\n",
    "    mfcc_train = []\n",
    "    data_train_class = merge_train.loc[merge_train['label'] == classes[i], ['x1','y1','z1','x2','y2','z2']]\n",
    "    for j in comb:\n",
    "      y = data_train_class.iloc[:,j]\n",
    "      y = y.to_numpy()\n",
    "      mfcc = librosa.feature.mfcc(y, sr, n_mfcc = 100, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "      mfcc_train.append(mfcc.T)\n",
    "\n",
    "    mfcc_train = np.vstack(mfcc_train)\n",
    "    gm = GaussianMixture(n_components=8, \n",
    "                          covariance_type='diag',\n",
    "                          random_state=100463947).fit(mfcc_train)\n",
    "    models.append(gm)\n",
    "\n",
    "  # predict based on highest loglike score\n",
    "  scores = []\n",
    "  mfcc_test = []\n",
    "  for j in comb:\n",
    "    y = X_real_test[:,j]\n",
    "    mfcc = librosa.feature.mfcc(y, sr, n_mfcc = 100, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "    mfcc_test.append(mfcc.T)\n",
    "\n",
    "  mfcc_test = np.vstack(mfcc_test)\n",
    "\n",
    "  for gmm in models:\n",
    "    loglike = gmm.score_samples(mfcc_test)\n",
    "    scores.append(loglike)\n",
    "  pred_level = np.argmax(scores, axis=0)+1\n",
    "\n",
    "  # need to select the appropriate labels to compare (the most repeated one for every 25 samples in the original signal)\n",
    "  # pred_level has each feature stacked on top of each other, so get labels and repeat sequence 6 times\n",
    "  j=0\n",
    "  new_labels = []\n",
    "  while j <= len(Y_real_test):\n",
    "    m = stats.mode(Y_real_test[j:j+24].ravel())[0]\n",
    "    new_labels.append(m)\n",
    "    j=j+25\n",
    "\n",
    "  new_labels = new_labels*len(comb)\n",
    "\n",
    "  print('accuracy score:',np.round(accuracy_score(new_labels,pred_level),2),'\\n') # 0.45\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fOUutXNiwSV"
   },
   "source": [
    "Best result is **0.64 accuracy**, using idx 0 (**only the first variable**).\n",
    "\n",
    "This validates our hypothesis that we may find a selection of features that will construct the best combination of MFCC.\n",
    "\n",
    "Now, we will finally search for the best model, in terms of the combination of features, and the number of MFCC (for the ensemble of best models).\n",
    "\n",
    "When trying all possible combinations, it was quickly obvious that we were not going to improve our results.\n",
    "\n",
    "Due to lack of computational resources , we will only the results that have the **first variable in them**, as it provides the best results, and groups of maximum 3 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWCzf7eIru0P"
   },
   "source": [
    "### 3.2. Classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nOYZf0tBru0W",
    "outputId": "b903f791-20b7-4b09-90d1-0e42dd3859e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model using variables with idx (0,)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.672\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.728\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.699\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.705\n",
      "\n",
      "\n",
      "model using variables with idx (0, 1)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.527\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.549\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.525\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.525\n",
      "\n",
      "\n",
      "model using variables with idx (0, 2)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.528\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.575\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.538\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.542\n",
      "\n",
      "\n",
      "model using variables with idx (0, 3)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.591\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.625\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.628\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.62\n",
      "\n",
      "\n",
      "model using variables with idx (0, 4)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.581\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.616\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.61\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.615\n",
      "\n",
      "\n",
      "model using variables with idx (0, 5)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.587\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.623\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.602\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.6\n",
      "\n",
      "\n",
      "model using variables with idx (0, 1, 2)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.517\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.55\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.516\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.519\n",
      "\n",
      "\n",
      "model using variables with idx (0, 1, 3)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.524\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.552\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.534\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.542\n",
      "\n",
      "\n",
      "model using variables with idx (0, 1, 4)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.514\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.541\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.505\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.516\n",
      "\n",
      "\n",
      "model using variables with idx (0, 1, 5)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.518\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.546\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.52\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.526\n",
      "\n",
      "\n",
      "model using variables with idx (0, 2, 3)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.517\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.543\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.512\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.517\n",
      "\n",
      "\n",
      "model using variables with idx (0, 2, 4)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.515\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.546\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.517\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.518\n",
      "\n",
      "\n",
      "model using variables with idx (0, 2, 5)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.525\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.558\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.527\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.528\n",
      "\n",
      "\n",
      "model using variables with idx (0, 3, 4)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.558\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.596\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.588\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.586\n",
      "\n",
      "\n",
      "model using variables with idx (0, 3, 5)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.559\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.598\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.591\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.591\n",
      "\n",
      "\n",
      "model using variables with idx (0, 4, 5)\n",
      "n_mfcc: 5\n",
      "accuracy score: 0.553\n",
      "n_mfcc: 10\n",
      "accuracy score: 0.595\n",
      "n_mfcc: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.579\n",
      "n_mfcc: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/discriminant_analysis.py:878: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.576\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "comb_lst = [com for sub in range(3) for com in combinations([0,1,2,3,4,5], sub + 1)]\n",
    "comb_lst2 = []\n",
    "for elem in comb_lst:\n",
    "    if 0 in elem:\n",
    "        comb_lst2.append(elem)\n",
    "\n",
    "# ensemble with soft voting\n",
    "classifiers = [\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    BaggingClassifier(random_state=100463947), \n",
    "    GradientBoostingClassifier(random_state=100463947), \n",
    "    RandomForestClassifier(random_state=100463947), \n",
    "    HistGradientBoostingClassifier(random_state=100463947)\n",
    "    ]\n",
    "initials = ['QDA','Bagg','GB','RF','HGB']\n",
    "\n",
    "e_list = [(i,c) for i,c in zip(initials,classifiers)]\n",
    "\n",
    "\n",
    "for comb in comb_lst2:\n",
    "  print('model using variables with idx', comb)\n",
    "  j=0\n",
    "  new_labels_train = []\n",
    "  while j <= Y.shape[0]:\n",
    "    m = stats.mode(Y[j:j+24].ravel())[0]\n",
    "    new_labels_train.append(m)\n",
    "    j=j+25\n",
    "\n",
    "  new_labels_train = new_labels_train*len(comb)\n",
    "\n",
    "\n",
    "  for k in range(5,25,5):\n",
    "    print('n_mfcc:',k)\n",
    "    mfcc_train = []\n",
    "    for j in comb:\n",
    "      y = X[:,j]\n",
    "      mfcc = librosa.feature.mfcc(y, sr, n_mfcc = k, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "      mfcc_train.append(mfcc.T)\n",
    "\n",
    "    mfcc_train = np.vstack(mfcc_train)\n",
    "    mfcc_test = []\n",
    "    for j in comb:\n",
    "      y = X_real_test[:,j]\n",
    "      mfcc = librosa.feature.mfcc(y, sr, n_mfcc = k, hop_length = sr, n_fft = sr, n_mels=20)\n",
    "      mfcc_test.append(mfcc.T)\n",
    "    \n",
    "    mfcc_test = np.vstack(mfcc_test)\n",
    "\n",
    "\n",
    "    j=0\n",
    "    new_labels_test = []\n",
    "    while j <= len(Y_real_test):\n",
    "      m = stats.mode(Y_real_test[j:j+24].ravel())[0]\n",
    "      new_labels_test.append(m)\n",
    "      j=j+25\n",
    "    new_labels_test = new_labels_test*len(comb)\n",
    "    \n",
    "    eclf = VotingClassifier(estimators=e_list, voting='soft')\n",
    "    eclf.fit(mfcc_train,np.array(new_labels_train).ravel())\n",
    "    pred = eclf.predict(mfcc_test)\n",
    "    score = round(metrics.accuracy_score(new_labels_test, pred),3)\n",
    "    print('accuracy score:',score)\n",
    "  print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzsw783dl6J7"
   },
   "source": [
    "The best results out of all these combinations is using **only the first variable and 10 MFCC**, with **0.728 accuracy**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WOA0ri9ol6kM"
   },
   "source": [
    "# Summary of leading results\n",
    "\n",
    "\n",
    "| model description | overall accuracy | sequence 1 accuracy | sequence 2 accuracy | sequence 3 accuracy |  \n",
    "| ----------------- | ---- | ------------- | -------- | --------- |  \n",
    "| GMM without id column | 0.73 | 0.72 | 0.72 | 0.79 | \n",
    "| QDA without id column | 0.74 | 0.732 | 0.725 | 0.779 |\n",
    "| Bagging without id column  | 0.742 | 0.678 | 0.801 | 0.818 |\n",
    "| RF without id column  | 0.744 | 0.675 | 0.816 | 0.815 |\n",
    "| Ensemble without id column | 0.766 | 0.704 | 0.813 | 0.848 |\n",
    "| **Ensemble with tuned parameters, without id column** | **0.771** | **0.712** | **0.817** | **0.852** |\n",
    "| QDA with id column | 0.737 | 0.72 | 0.743 | 0.769 |\n",
    "| One model per sequence | 0.744 | 0.669 | 0.835 | 0.803 | \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "S0ZlqrdrS9te",
    "wlMtB2c7r-Po",
    "_fRptjT1t-z2",
    "NvT08INP-7IB",
    "_1bYRY0Vepim"
   ],
   "name": "DASS_lab4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
